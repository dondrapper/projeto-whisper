"""
M√≥dulo para transcri√ß√£o de √°udio usando o modelo Whisper da OpenAI.
Vers√£o melhorada com configura√ß√µes avan√ßadas e otimiza√ß√µes.
"""

import whisper
import torch
import streamlit as st
import os
import time
import numpy as np
from utils import format_time

# Verifica se CUDA est√° dispon√≠vel para processamento em GPU
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# Lista de modelos dispon√≠veis com informa√ß√µes detalhadas
MODELS = {
    "tiny": {
        "description": "Mais r√°pido, menos preciso",
        "memory": "1GB",
        "speed": "‚ö°‚ö°‚ö°‚ö°‚ö°",
        "accuracy": "‚≠ê‚≠ê",
        "languages": "üåç Limitado"
    },
    "base": {
        "description": "R√°pido, precis√£o razo√°vel", 
        "memory": "1GB",
        "speed": "‚ö°‚ö°‚ö°‚ö°",
        "accuracy": "‚≠ê‚≠ê‚≠ê",
        "languages": "üåç Bom"
    },
    "small": {
        "description": "Bom equil√≠brio velocidade/precis√£o",
        "memory": "2GB", 
        "speed": "‚ö°‚ö°‚ö°",
        "accuracy": "‚≠ê‚≠ê‚≠ê‚≠ê",
        "languages": "üåç Muito Bom"
    },
    "medium": {
        "description": "Mais preciso, menos r√°pido",
        "memory": "5GB",
        "speed": "‚ö°‚ö°",
        "accuracy": "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê",
        "languages": "üåç Excelente"
    },
    "large-v2": {
        "description": "M√°xima precis√£o, multil√≠ngue",
        "memory": "10GB",
        "speed": "‚ö°",
        "accuracy": "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê",
        "languages": "üåç Perfeito"
    }
}

# Mapeia idiomas com c√≥digos ISO
LANGUAGES = {
    "auto": "üîç Detec√ß√£o autom√°tica",
    "pt": "üáßüá∑ Portugu√™s", 
    "en": "üá∫üá∏ Ingl√™s",
    "es": "üá™üá∏ Espanhol",
    "fr": "üá´üá∑ Franc√™s",
    "de": "üá©üá™ Alem√£o",
    "it": "üáÆüáπ Italiano",
    "ja": "üáØüáµ Japon√™s",
    "zh": "üá®üá≥ Chin√™s",
    "ru": "üá∑üá∫ Russo",
    "ko": "üá∞üá∑ Coreano",
    "ar": "üá∏üá¶ √Årabe",
    "hi": "üáÆüá≥ Hindi",
    "nl": "üá≥üá± Holand√™s",
    "pl": "üáµüá± Polon√™s",
    "sv": "üá∏üá™ Sueco",
    "no": "üá≥üá¥ Noruegu√™s",
    "da": "üá©üá∞ Dinamarqu√™s",
    "fi": "üá´üáÆ Finland√™s",
    "tr": "üáπüá∑ Turco",
    "uk": "üá∫üá¶ Ucraniano",
    "cs": "üá®üáø Tcheco",
    "hu": "üá≠üá∫ H√∫ngaro",
    "th": "üáπüá≠ Tailand√™s",
    "vi": "üáªüá≥ Vietnamita",
    "he": "üáÆüá± Hebraico"
}

# Presets de qualidade
QUALITY_PRESETS = {
    "fast": {
        "beam_size": 1,
        "best_of": 1,
        "temperature": 0.0,
        "compression_ratio_threshold": 2.4,
        "logprob_threshold": -1.0,
        "no_speech_threshold": 0.6
    },
    "balanced": {
        "beam_size": 3,
        "best_of": 3,
        "temperature": 0.0,
        "compression_ratio_threshold": 2.0,
        "logprob_threshold": -0.5,
        "no_speech_threshold": 0.5
    },
    "high_quality": {
        "beam_size": 5,
        "best_of": 5,
        "temperature": 0.0,
        "compression_ratio_threshold": 1.8,
        "logprob_threshold": -0.3,
        "no_speech_threshold": 0.4
    }
}

@st.cache_resource(show_spinner="üîÑ Carregando modelo de transcri√ß√£o...")
def load_whisper_model(model_size):
    """
    Carrega o modelo Whisper com o tamanho especificado.
    
    Args:
        model_size (str): Tamanho do modelo (tiny, base, small, medium, large-v2)
        
    Returns:
        modelo Whisper carregado
    """
    try:
        # Configurar device adequadamente
        if DEVICE == "cuda":
            torch.cuda.empty_cache()  # Limpar cache da GPU
        
        model = whisper.load_model(model_size, device=DEVICE)
        
        # Log de informa√ß√µes do modelo
        st.sidebar.success(f"‚úÖ Modelo {model_size} carregado com sucesso!")
        
        return model
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar modelo {model_size}: {str(e)}")
        # Fallback para modelo menor
        if model_size != "tiny":
            st.warning("üîÑ Tentando carregar modelo 'tiny' como fallback...")
            return whisper.load_model("tiny", device=DEVICE)
        else:
            raise e

def transcribe_audio(audio_path, model, language="auto", task="transcribe", advanced_options=None):
    """
    Transcreve um arquivo de √°udio usando o modelo Whisper.
    
    Args:
        audio_path (str): Caminho para o arquivo de √°udio
        model: Modelo Whisper carregado
        language (str): C√≥digo do idioma ou "auto" para detec√ß√£o
        task (str): "transcribe" ou "translate" (para traduzir para ingl√™s)
        advanced_options (dict): Configura√ß√µes avan√ßadas
        
    Returns:
        dict: Resultado da transcri√ß√£o com texto e metadados
    """
    start_time = time.time()
    
    # Configura√ß√µes padr√£o
    if advanced_options is None:
        advanced_options = {}
    
    # Aplicar preset de qualidade
    quality_preset = advanced_options.get("quality_preset", "balanced")
    preset_config = QUALITY_PRESETS.get(quality_preset, QUALITY_PRESETS["balanced"])
    
    # Configura√ß√£o de op√ß√µes
    options = {
        "task": task,
        "fp16": DEVICE == "cuda",  # Usar fp16 apenas se tiver GPU
        "verbose": False,  # Reduzir sa√≠da desnecess√°ria
        "word_timestamps": True,  # Habilitar timestamps de palavras
        **preset_config
    }
    
    # Aplicar configura√ß√µes avan√ßadas personalizadas
    if "temperature" in advanced_options:
        options["temperature"] = advanced_options["temperature"]
    if "beam_size" in advanced_options:
        options["beam_size"] = advanced_options["beam_size"]
    
    # Configurar idioma se especificado
    if language != "auto":
        options["language"] = language
    
    try:
        # Executar transcri√ß√£o
        with torch.no_grad():  # Otimiza√ß√£o de mem√≥ria
            result = model.transcribe(audio_path, **options)
        
        # Calcular tempo de processamento
        processing_time = time.time() - start_time
        
        # Processar e enriquecer resultados
        result = enhance_transcription_result(result, processing_time, advanced_options)
        
        # Limpeza de mem√≥ria
        if DEVICE == "cuda":
            torch.cuda.empty_cache()
        
        return result
        
    except Exception as e:
        # Limpeza em caso de erro
        if DEVICE == "cuda":
            torch.cuda.empty_cache()
        raise Exception(f"Erro durante a transcri√ß√£o: {str(e)}")

def enhance_transcription_result(result, processing_time, advanced_options):
    """
    Enriquece o resultado da transcri√ß√£o com metadados adicionais.
    
    Args:
        result (dict): Resultado bruto do Whisper
        processing_time (float): Tempo de processamento
        advanced_options (dict): Configura√ß√µes utilizadas
        
    Returns:
        dict: Resultado enriquecido
    """
    # Adicionar metadados de processamento
    result["processing_time"] = processing_time
    result["processing_time_formatted"] = format_time(processing_time)
    result["advanced_options_used"] = advanced_options
    
    # Calcular estat√≠sticas dos segmentos
    if "segments" in result:
        segments = result["segments"]
        
        # Calcular confian√ßa m√©dia
        total_confidence = 0
        confidence_count = 0
        
        for segment in segments:
            if "words" in segment:
                for word in segment["words"]:
                    if "probability" in word:
                        total_confidence += word["probability"]
                        confidence_count += 1
        
        result["average_confidence"] = total_confidence / confidence_count if confidence_count > 0 else 0.5
        
        # Calcular dura√ß√£o total do √°udio
        if segments:
            result["audio_duration"] = segments[-1].get("end", 0)
            result["audio_duration_formatted"] = format_time(result["audio_duration"])
        
        # Estat√≠sticas de velocidade
        if result.get("audio_duration", 0) > 0:
            result["processing_speed_ratio"] = processing_time / result["audio_duration"]
            result["realtime_factor"] = result["audio_duration"] / processing_time
        
        # Filtrar segmentos por confian√ßa se solicitado
        confidence_threshold = advanced_options.get("confidence_threshold", 0.0)
        if confidence_threshold > 0:
            result["segments"] = filter_segments_by_confidence(segments, confidence_threshold)
            result["filtered_segments_count"] = len(result["segments"])
    
    # Detectar caracter√≠sticas do √°udio
    result["audio_characteristics"] = analyze_audio_characteristics(result)
    
    return result

def filter_segments_by_confidence(segments, threshold):
    """
    Filtra segmentos baseado no threshold de confian√ßa.
    
    Args:
        segments (list): Lista de segmentos
        threshold (float): Threshold de confian√ßa (0.0 a 1.0)
        
    Returns:
        list: Segmentos filtrados
    """
    filtered_segments = []
    
    for segment in segments:
        segment_confidence = 0.5  # Valor padr√£o
        
        if "words" in segment:
            word_confidences = [word.get("probability", 0.5) for word in segment["words"]]
            if word_confidences:
                segment_confidence = sum(word_confidences) / len(word_confidences)
        
        if segment_confidence >= threshold:
            segment["confidence"] = segment_confidence
            filtered_segments.append(segment)
    
    return filtered_segments

def analyze_audio_characteristics(result):
    """
    Analisa caracter√≠sticas do √°udio baseado na transcri√ß√£o.
    
    Args:
        result (dict): Resultado da transcri√ß√£o
        
    Returns:
        dict: Caracter√≠sticas detectadas
    """
    characteristics = {
        "speech_rate": "normal",
        "has_silence": False,
        "language_confidence": "medium",
        "audio_quality": "good"
    }
    
    if "segments" in result and result["segments"]:
        segments = result["segments"]
        
        # Calcular taxa de fala (palavras por minuto)
        total_words = sum(len(segment.get("text", "").split()) for segment in segments)
        total_duration = result.get("audio_duration", 0)
        
        if total_duration > 0:
            words_per_minute = (total_words / total_duration) * 60
            
            if words_per_minute < 120:
                characteristics["speech_rate"] = "slow"
            elif words_per_minute > 180:
                characteristics["speech_rate"] = "fast"
            else:
                characteristics["speech_rate"] = "normal"
        
        # Detectar pausas longas (poss√≠veis sil√™ncios)
        for i in range(len(segments) - 1):
            gap = segments[i + 1]["start"] - segments[i]["end"]
            if gap > 3.0:  # Pausa maior que 3 segundos
                characteristics["has_silence"] = True
                break
        
        # Avaliar confian√ßa da detec√ß√£o de idioma
        avg_confidence = result.get("average_confidence", 0.5)
        if avg_confidence > 0.8:
            characteristics["language_confidence"] = "high"
        elif avg_confidence < 0.4:
            characteristics["language_confidence"] = "low"
        
        # Avaliar qualidade baseada na confian√ßa e repeti√ß√µes
        if avg_confidence > 0.7:
            characteristics["audio_quality"] = "excellent"
        elif avg_confidence > 0.5:
            characteristics["audio_quality"] = "good"
        elif avg_confidence > 0.3:
            characteristics["audio_quality"] = "fair"
        else:
            characteristics["audio_quality"] = "poor"
    
    return characteristics

def get_model_recommendations(file_size_mb, device_type):
    """
    Recomenda o melhor modelo baseado no tamanho do arquivo e dispositivo.
    
    Args:
        file_size_mb (float): Tamanho do arquivo em MB
        device_type (str): Tipo de dispositivo ("cuda" ou "cpu")
        
    Returns:
        str: Modelo recomendado
    """
    if device_type == "cpu":
        if file_size_mb < 10:
            return "base"
        elif file_size_mb < 50:
            return "small"
        else:
            return "base"  # Para CPU, evitar modelos muito grandes
    else:  # GPU
        if file_size_mb < 5:
            return "small"
        elif file_size_mb < 25:
            return "medium"
        else:
            return "large-v2"

def optimize_for_device():
    """
    Otimiza configura√ß√µes baseadas no dispositivo dispon√≠vel.
    
    Returns:
        dict: Configura√ß√µes otimizadas
    """
    config = {
        "device": DEVICE,
        "recommended_models": [],
        "max_file_size_mb": 100,
        "parallel_processing": False
    }
    
    if DEVICE == "cuda":
        # Configura√ß√µes para GPU
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        
        if gpu_memory >= 8:
            config["recommended_models"] = ["medium", "large-v2"]
            config["max_file_size_mb"] = 500
            config["parallel_processing"] = True
        elif gpu_memory >= 4:
            config["recommended_models"] = ["small", "medium"]
            config["max_file_size_mb"] = 250
        else:
            config["recommended_models"] = ["tiny", "base", "small"]
            config["max_file_size_mb"] = 100
    else:
        # Configura√ß√µes para CPU
        config["recommended_models"] = ["tiny", "base"]
        config["max_file_size_mb"] = 50
    
    return config

# Inicializar configura√ß√µes do dispositivo
DEVICE_CONFIG = optimize_for_device()